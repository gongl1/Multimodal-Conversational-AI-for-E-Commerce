{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install openai==0.28.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzQ7de3fywXL",
        "outputId": "0afe2faa-7028-4c25-fc21-c7a56bc6bc3e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: openai==0.28.0 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (3.11.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28.0) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfnJAwXTuEsb",
        "outputId": "8f1709b3-6369-43ad-b5fe-720baeed233a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"app_for_colab.ipynb\"\"\"\n",
        "\n",
        "import os\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import requests\n",
        "import torch\n",
        "import openai\n",
        "\n",
        "# Load the CLIP model and processor\n",
        "def load_clip_model():\n",
        "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "    return model, processor\n",
        "\n",
        "clip_model, clip_processor = load_clip_model()\n",
        "\n",
        "# Helper function to download files\n",
        "def download_file(url, save_path):\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "        return save_path\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        raise Exception(f\"Failed to download {url}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load FAISS indices\n",
        "def load_faiss_indices():\n",
        "    indices = {\n",
        "        \"text_only\": \"https://drive.google.com/uc?id=1c6GoqDAFgvVLzr4tcazLb6NS2ZbKRK_i\",\n",
        "        \"image_only\": \"https://drive.google.com/uc?id=1CNfRQdtnokIckOjjkZgG4M_DZtV9_zJr\",\n",
        "        \"multimodal_embeddings\": \"https://drive.google.com/uc?id=1lAKVwo1d0YK8KBtdk_A-UCzpVBH3Pl7d\",\n",
        "    }\n",
        "    temp_dir = \"temp_indices\"\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    loaded_indices = {}\n",
        "    for name, url in indices.items():\n",
        "        save_path = os.path.join(temp_dir, f\"{name}.index\")\n",
        "        if not os.path.exists(save_path):\n",
        "            download_file(url, save_path)\n",
        "        try:\n",
        "            loaded_indices[name] = faiss.read_index(save_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load FAISS index for {name}: {e}\")\n",
        "\n",
        "    return (\n",
        "        loaded_indices.get(\"text_only\"),\n",
        "        loaded_indices.get(\"image_only\"),\n",
        "        loaded_indices.get(\"multimodal_embeddings\"),\n",
        "    )\n",
        "\n",
        "text_index, image_index, full_index = load_faiss_indices()"
      ],
      "metadata": {
        "id": "W_6Kv6TywW7b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gdown\n",
        "\n",
        "# Step 1: Define the file path where the dataset will be saved\n",
        "save_path = \"final_dataset.csv\"\n",
        "\n",
        "# Step 2: Download the dataset using gdown\n",
        "file_id = \"104LiRhqzx4prsVQ__Lk-2rR92YzkDI7_\"  # Replace with your file's ID\n",
        "dataset_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "gdown.download(dataset_url, save_path, quiet=False)\n",
        "\n",
        "# Step 3: Load the dataset\n",
        "try:\n",
        "    final_dataset = pd.read_csv(save_path, encoding='utf-8')  # Adjust encoding if needed\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    print(final_dataset.head())  # Display the first few rows of the dataset\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the dataset: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu_YHYQgwcwh",
        "outputId": "8183cc26-07aa-4d06-89c5-9c60213e1fcb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=104LiRhqzx4prsVQ__Lk-2rR92YzkDI7_\n",
            "From (redirected): https://drive.google.com/uc?id=104LiRhqzx4prsVQ__Lk-2rR92YzkDI7_&confirm=t&uuid=e99ad5ba-ae2d-47f3-b65d-f1fb39c7942c\n",
            "To: /content/final_dataset.csv\n",
            "100%|██████████| 31.8M/31.8M [00:00<00:00, 96.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "                                Product Name_Cleaned  \\\n",
            "0  db longboards coreflex crossbow 41\" bamboo fib...   \n",
            "1  electronic snap circuits mini kits classpack, ...   \n",
            "2  3doodler create flexy 3d printing filament ref...   \n",
            "3  guillow airplane design studio with travel cas...   \n",
            "4                   woodstock- collage 500 pc puzzle   \n",
            "\n",
            "                                    Category_Cleaned  Selling Price_Cleaned  \\\n",
            "0  sports & outdoors   outdoor recreation   skate...                 237.68   \n",
            "1  toys & games   learning & education   science ...                  99.95   \n",
            "2          toys & games   arts & crafts   craft kits                  34.99   \n",
            "3  toys & games   hobbies   models & model kits  ...                  28.91   \n",
            "4            toys & games   puzzles   jigsaw puzzles                  17.49   \n",
            "\n",
            "                               About Product_Cleaned  \\\n",
            "0  make sure this fits by entering your model num...   \n",
            "1  make sure this fits by entering your model num...   \n",
            "2  make sure this fits by entering your model num...   \n",
            "3  make 8 different planes at one time.   experim...   \n",
            "4  make sure this fits by entering your model num...   \n",
            "\n",
            "                       Product Specification_Cleaned  \\\n",
            "0  shipping weight: 10.7 pounds (view shipping ra...   \n",
            "1  product dimensions:         14.7 x 11.1 x 10.2...   \n",
            "2  productdimensions:10.3x3.4x0.8inches itemweigh...   \n",
            "3  productdimensions:3.5x6.2x13inches itemweight:...   \n",
            "4  productdimensions:1.9x8x10inches itemweight:13...   \n",
            "\n",
            "                           Technical Details_Cleaned  Shipping Weight_Cleaned  \\\n",
            "0                                                NaN                    10.70   \n",
            "1  the snap circuits mini kits classpack provides...                     4.00   \n",
            "2  show up to 2 reviews by default no longer are ...                     0.80   \n",
            "3  go to your orders and start the return select ...                     0.84   \n",
            "4  show up to 2 reviews by default 100% officiall...                     0.84   \n",
            "\n",
            "                                               Image  \\\n",
            "0  https://images-na.ssl-images-amazon.com/images...   \n",
            "1  https://images-na.ssl-images-amazon.com/images...   \n",
            "2  https://images-na.ssl-images-amazon.com/images...   \n",
            "3  https://images-na.ssl-images-amazon.com/images...   \n",
            "4  https://images-na.ssl-images-amazon.com/images...   \n",
            "\n",
            "                                         Product Url  \\\n",
            "0  https://www.amazon.com/DB-Longboards-CoreFlex-...   \n",
            "1  https://www.amazon.com/Electronic-Circuits-Cla...   \n",
            "2  https://www.amazon.com/3Doodler-Plastic-Innova...   \n",
            "3  https://www.amazon.com/Guillow-Airplane-Design...   \n",
            "4  https://www.amazon.com/Woodstock-Collage-500-p...   \n",
            "\n",
            "   Is Amazon Seller_Cleaned                                      Combined_Text  \n",
            "0                      True  db longboards coreflex crossbow 41\" bamboo fib...  \n",
            "1                      True  electronic snap circuits mini kits classpack, ...  \n",
            "2                      True  3doodler create flexy 3d printing filament ref...  \n",
            "3                      True  guillow airplane design studio with travel cas...  \n",
            "4                      True  woodstock- collage 500 pc puzzle toys & games ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set OpenAI API key\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "QZhn97r2wgZp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "def preprocess_image(image):\n",
        "    \"\"\"Preprocess an image for CLIP.\"\"\"\n",
        "    return clip_processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "def generate_text_embeddings(texts):\n",
        "    \"\"\"Generate text embeddings using CLIP.\"\"\"\n",
        "    inputs = clip_processor(text=texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        return clip_model.get_text_features(**inputs).cpu().numpy()\n",
        "\n",
        "def generate_image_embeddings(images):\n",
        "    \"\"\"Generate image embeddings using CLIP.\"\"\"\n",
        "    embeddings = []\n",
        "    for image in images:\n",
        "        inputs = preprocess_image(image)\n",
        "        with torch.no_grad():\n",
        "            embeddings.append(clip_model.get_image_features(**inputs).cpu().numpy())\n",
        "    return np.vstack(embeddings)"
      ],
      "metadata": {
        "id": "JvQgel3jwksW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_gpt4(query, retrieved_items):\n",
        "    \"\"\"Generate a conversational response using GPT-4.\"\"\"\n",
        "    if retrieved_items.empty:\n",
        "        return f\"Sorry, I couldn't find any relevant products for your query: {query}\"\n",
        "\n",
        "    # Create a structured context from retrieved items\n",
        "    context = \"\\n\".join(\n",
        "        [\n",
        "            f\"{i+1}. {row['Product Name_Cleaned']}: {row['About Product_Cleaned']} \"\n",
        "            f\"(Category: {row['Category_Cleaned']}, Price: {row['Selling Price_Cleaned']}, \"\n",
        "            f\"Image URL: {row['Image']})\"\n",
        "            for i, row in retrieved_items.iterrows()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Create GPT-4 prompt\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful assistant recommending products based on user queries.\n",
        "\n",
        "    Context:\n",
        "    Here are some products relevant to the user's query:\n",
        "    {context}\n",
        "\n",
        "    Based on the query, recommend the most suitable product(s) and explain why they meet the user's needs.\n",
        "    If the query asks for a specific product image, include the image URL in the response.\n",
        "\n",
        "    Question: {query}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate response using GPT-4\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a friendly, knowledgeable assistant helping users find products.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        max_tokens=300,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "Gc86viS4wqLU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage in Colab\n",
        "query_type = input(\"Select Query Type (Text, Image, Multimodal): \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxuEnO80wt44",
        "outputId": "e67ac143-82a1-408b-ff43-b16be9aa0786"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Select Query Type (Text, Image, Multimodal): Multimodal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"Enter your query (for text and multimodal queries): \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBtn1iSXz4nC",
        "outputId": "5a20d031-1015-4ff2-f287-031bd856811e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query (for text and multimodal queries): What is the name of this product, and how do I use it effectively?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files  # Import the files module\n",
        "\n",
        "# Step 1: Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Extract the filename and save the uploaded file locally\n",
        "uploaded_file_path = list(uploaded.keys())[0]\n",
        "with open(uploaded_file_path, \"wb\") as f:\n",
        "    f.write(uploaded[uploaded_file_path])  # Save the binary content to a file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Jcpxg0Q_z-cH",
        "outputId": "97c4cc36-5156-49de-a3cc-729ff5d61c1c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28284628-3df4-4a39-8906-232eae1bb259\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28284628-3df4-4a39-8906-232eae1bb259\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1.jpg to 1.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Process text query\n",
        "    text_embedding = None\n",
        "    image_embedding = None\n",
        "\n",
        "    if query_type in [\"Text\", \"Multimodal\"] and query:\n",
        "        text_embedding = generate_text_embeddings([query])\n",
        "\n",
        "    if query_type in [\"Image\", \"Multimodal\"] and uploaded_file_path:\n",
        "        image = Image.open(uploaded_file_path).convert(\"RGB\")\n",
        "        image_embedding = generate_image_embeddings([image])\n",
        "\n",
        "    # Combine embeddings for multimodal query\n",
        "    if query_type == \"Multimodal\" and text_embedding is not None and image_embedding is not None:\n",
        "        multimodal_embedding = np.hstack([text_embedding, image_embedding])\n",
        "        index_to_use = full_index\n",
        "    elif query_type == \"Text\" and text_embedding is not None:\n",
        "        multimodal_embedding = text_embedding\n",
        "        index_to_use = text_index\n",
        "    elif query_type == \"Image\" and image_embedding is not None:\n",
        "        multimodal_embedding = image_embedding\n",
        "        index_to_use = image_index\n",
        "    else:\n",
        "        print(\"Please provide a valid query!\")\n",
        "        exit()\n",
        "\n",
        "    # Perform search\n",
        "    distances, indices = index_to_use.search(multimodal_embedding, k=1)\n",
        "\n",
        "    # Ensure indices are within bounds\n",
        "    valid_indices = [i for i in indices.flatten() if i < len(final_dataset)]\n",
        "    retrieved_items = final_dataset.iloc[valid_indices]\n",
        "\n",
        "    # Display results\n",
        "    print(\"Retrieved Results:\")\n",
        "    for _, row in retrieved_items.iterrows():\n",
        "        print(f\"**{row['Product Name_Cleaned']}**\")\n",
        "        print(f\"Category: {row['Category_Cleaned']}\")\n",
        "        print(f\"Price: {row['Selling Price_Cleaned']}\")\n",
        "        print(f\"[Product Link]({row['Product Url']})\")\n",
        "        print(f\"Image: {row['Image']}\")\n",
        "\n",
        "    # Generate GPT-4 response\n",
        "    gpt_response = generate_response_gpt4(query or \"image-based query\", retrieved_items)\n",
        "    print(\"\\nGPT-4 Response:\")\n",
        "    print(gpt_response)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1_Wa9cNw1nk",
        "outputId": "83291ff4-1dca-4f5d-ebfe-8903e766c106"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved Results:\n",
            "**pokemon tcg: sun and moon crimson invasion elite trainer box**\n",
            "Category: nan\n",
            "Price: 38.49\n",
            "[Product Link](https://www.amazon.com/Pokemon-TCG-Crimson-Invasion-Trainer/dp/B074NCGNX2)\n",
            "Image: https://images-na.ssl-images-amazon.com/images/I/51LFAQfMX6L.jpg|https://images-na.ssl-images-amazon.com/images/G/01/x-locale/common/transparent-pixel.jpg\n",
            "\n",
            "GPT-4 Response:\n",
            "The name of the product is \"Pokemon TCG: Sun and Moon Crimson Invasion Elite Trainer Box\". \n",
            "\n",
            "This product is used for playing the Pokemon Trading Card Game. To use it effectively, you would first have to familiarize yourself with the rules of the game. The box includes a player's guide to the Sun & Moon—Crimson Invasion expansion, which should help you understand the specifics of this version of the game. \n",
            "\n",
            "The box includes 8 booster packs which contain random cards that you can add to your deck. The card sleeves featuring Silvally are used to protect your cards from damage. The 45 energy cards are a fundamental part of the game as they are used to power your Pokemon's attacks. \n",
            "\n",
            "The box also includes 6 damage-counter dice, 2 acrylic condition markers, and 1 acrylic GX marker which are used to track the state of play during a game. The competition-legal coin-flip die is used to decide who goes first and to resolve certain game situations.\n",
            "\n",
            "Finally, the collector's box itself can be used to store all these items and keep them organized with the included dividers. \n",
            "\n",
            "The product image URL is: \n",
            "https://images-na.ssl-images-amazon.com/images/I/51LFAQfMX6L.jpg|https://images-na.ssl-images-amazon.com/images/G/01/x-locale/common/transparent-pixel.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_items"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "3wBdZKIr2A4j",
        "outputId": "c8723cdd-7d1b-434d-9601-7dce49263ac0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                Product Name_Cleaned Category_Cleaned  \\\n",
              "9  pokemon tcg: sun and moon crimson invasion eli...              NaN   \n",
              "\n",
              "   Selling Price_Cleaned                              About Product_Cleaned  \\\n",
              "9                  38.49  make sure this fits by entering your model num...   \n",
              "\n",
              "                       Product Specification_Cleaned  \\\n",
              "9  productdimensions:7.5x3.5x6.8inches itemweight...   \n",
              "\n",
              "                           Technical Details_Cleaned  Shipping Weight_Cleaned  \\\n",
              "9  show up to 2 reviews by default crimson choas ...                      1.5   \n",
              "\n",
              "                                               Image  \\\n",
              "9  https://images-na.ssl-images-amazon.com/images...   \n",
              "\n",
              "                                         Product Url  \\\n",
              "9  https://www.amazon.com/Pokemon-TCG-Crimson-Inv...   \n",
              "\n",
              "   Is Amazon Seller_Cleaned                                      Combined_Text  \n",
              "9                      True  pokemon tcg: sun and moon crimson invasion eli...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5a4bfc3-cea2-4a76-a52f-a47e711c7ac0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name_Cleaned</th>\n",
              "      <th>Category_Cleaned</th>\n",
              "      <th>Selling Price_Cleaned</th>\n",
              "      <th>About Product_Cleaned</th>\n",
              "      <th>Product Specification_Cleaned</th>\n",
              "      <th>Technical Details_Cleaned</th>\n",
              "      <th>Shipping Weight_Cleaned</th>\n",
              "      <th>Image</th>\n",
              "      <th>Product Url</th>\n",
              "      <th>Is Amazon Seller_Cleaned</th>\n",
              "      <th>Combined_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pokemon tcg: sun and moon crimson invasion eli...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38.49</td>\n",
              "      <td>make sure this fits by entering your model num...</td>\n",
              "      <td>productdimensions:7.5x3.5x6.8inches itemweight...</td>\n",
              "      <td>show up to 2 reviews by default crimson choas ...</td>\n",
              "      <td>1.5</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>https://www.amazon.com/Pokemon-TCG-Crimson-Inv...</td>\n",
              "      <td>True</td>\n",
              "      <td>pokemon tcg: sun and moon crimson invasion eli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5a4bfc3-cea2-4a76-a52f-a47e711c7ac0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5a4bfc3-cea2-4a76-a52f-a47e711c7ac0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5a4bfc3-cea2-4a76-a52f-a47e711c7ac0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_eb1825b1-6622-4d68-bd6c-819a295ba8a0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('retrieved_items')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eb1825b1-6622-4d68-bd6c-819a295ba8a0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('retrieved_items');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "retrieved_items",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}